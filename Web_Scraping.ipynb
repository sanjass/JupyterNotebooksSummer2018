{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper\n",
    "### Shell internship summer 2018 - Sanja Simonovikj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Build a web scraper to extract text from articles from certain websites.\n",
    "\n",
    "**The websites we are going to scrape are the following: **\n",
    "- Energy Intelligence : http://www.energyintel.com \n",
    "- IHS -Energy, energy news on demand:  https://my.ihs.com/Energy \n",
    "- World Energy News: https://www.worldenergynews.com/\n",
    "\n",
    "Other websites to consider:\n",
    "- CNBS: https://www.cnbc.com/\n",
    "    - energy: https://www.cnbc.com/energy/\n",
    "    - oil and gas: https://www.cnbc.com/oil-gas/\n",
    "    - utilities: https://www.cnbc.com/oil-gas/\n",
    "    - renawable energy: https://www.cnbc.com/renewable-energy/\n",
    "- Economic Times: https://economictimes.indiatimes.com/\n",
    "    - Power: https://economictimes.indiatimes.com/industry/energy/power/articlelist/msid-13358361,contenttype-a.cms\n",
    "    - Oil and gas: https://economictimes.indiatimes.com/industry/energy/oil-gas/articlelist/msid-13358368,contenttype-a.cms\n",
    "   \n",
    "- Wall Street Journal - Energy: https://www.wsj.com/news/business/energy-oil-gas\n",
    "- Reuters- Global Energy news: https://in.reuters.com/news/archive/globalEnergyNews\n",
    "- Oil price: https://oilprice.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium Python\n",
    "\n",
    "Selenium python is an API which can automate interaction with a browser through a python script. Selenium is generally used for automated testing, but it can easily be used for stuff like web scraping. We prefer Selenium over other API's as it provides an easy way to log in to websites which require authentication. The only exception is that is is not possible to do this if the website uses CAPTCHA, as CAPTCHA's purpose is to prevent automated bots to navigate the website. To use Selenium one needs to have python, the selenium python package and webdriver (like chromedriver).\n",
    "\n",
    "- Documentation:  http://selenium-python.readthedocs.io/installation.html#introduction\n",
    "- Tutorial: http://www.marinamele.com/selenium-tutorial-web-scraping-with-selenium-and-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated scraping\n",
    "One can easily run all the python scripts simultaneously using bash script and get the text files within minutes. Furthermore, this can be automated to run periodically, so that one does not have to manually initiate the process. The runtime of the scripts varies from website to website; one can check the exact runtime at the last line of the output of running the script (given below). As of now, the runtime ranges from 1-6 minutes to scrape the homepage of a website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for scraping various websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Intelligence\n",
    ">  http://www.energyintel.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Script for scraping text from articles from Energy Intelligence website\n",
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "URL = \"https://www.energyintel.com/pages/non-subscriber.aspx\" # initial page with the login form\n",
    "TIMEOUT = 40 # how many seconds to wait for page to load before searching for an element, increasing this might prevent errors\n",
    "DATA_FOLDER = \"scraped_EI\" # folder to save the scraped aricles\n",
    "USERNAME = \"n.ghodke@shell.com\"\n",
    "PASSWORD = \"Forintern1\"\n",
    "\n",
    "browser = webdriver.Chrome(executable_path=os.path.abspath(\"chromedriver\")) #replace with .Firefox(), or with the browser of your choice\n",
    "# The chromdriver executable needs to be in the same folder as this script\n",
    "browser.get(URL) # navigate to the page\n",
    "\n",
    "username = browser.find_element_by_id(\"ctl00_Header_uc_login1_UserName\") #username form field\n",
    "password = browser.find_element_by_id(\"ctl00_Header_uc_login1_pwd\") #password form field\n",
    "\n",
    "\n",
    "username.send_keys(USERNAME) # populate the form\n",
    "if password.is_displayed():\n",
    "\t# if password is not visible (cached) this will not be executed\n",
    "\tpassword.send_keys(PASSWORD)\n",
    "\n",
    "\n",
    "submitButton = browser.find_element_by_id(\"ctl00_Header_uc_login1_imglogin\") \n",
    "submitButton.click()  # submit the login info\n",
    "\n",
    "\n",
    "articles = browser.find_elements_by_class_name('newsletter_headline')\n",
    "articles = [article for article in articles if \".pdf\" not in article.get_attribute('href')]\n",
    "urls = [i.get_attribute('href') for i in articles] # urls of articles\n",
    "\n",
    "print(\"Number of articles to be scraped: \", len(urls))\n",
    "\n",
    "i=0\n",
    "# iterate through article links\n",
    "for url in urls:\n",
    "\tbrowser.get(url)  \n",
    "\tscraped_text = \"\"\n",
    "\ttry:\n",
    "\t    WebDriverWait(browser, TIMEOUT).until(EC.visibility_of_element_located((By.XPATH,'//*[@id=\"divArticleHpContent\"]/table/tbody/tr[6]/td')))\n",
    "\texcept TimeoutException:\n",
    "\t    print(\"Timed out waiting for page to load\")\n",
    "\t    browser.quit()\n",
    "\n",
    "\ttitle = browser.find_element_by_xpath('//*[@id=\"divArticleHpContent\"]/table/tbody/tr[6]/td')\n",
    "\tprint(\"Article \" + str(i+1) + \" currently scraped: \", title.text)\n",
    "\tscraped_text += title.text + \"\\n\"\n",
    "\trecords = browser.find_elements_by_xpath('//*[@id=\"divArticleHpContent\"]/table/tbody/tr[7]/td/div')\n",
    "\tfor record in records:\n",
    "\t\tfor paragraph in record.find_elements_by_xpath('.//p'):\n",
    "\t\t\tscraped_text += paragraph.text + \"\\n\"\n",
    "\ttimestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\twith open(os.path.join(DATA_FOLDER,\"doc_\" + timestr + \"_\" + \".txt\"), 'w') as d:\n",
    "\t\td.write(scraped_text) # write the scraped text in a document\n",
    "\n",
    "\ti+=1\n",
    "\n",
    "\n",
    "print(\"Time report: It took \" +str((datetime.now() - startTime).total_seconds())+ \" seconds to run this script\")\n",
    "time.sleep(1)\n",
    "browser.quit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "```\n",
    "Number of articles to be scraped:  17\n",
    "Article 1 currently scraped:  US Oil Lobby Backs Bill to Check Trump's Trade Authority\n",
    "Article 2 currently scraped:  Denmark Plays Coy on Nord Stream 2 Permit Approval\n",
    "Article 3 currently scraped:  Kuwait Energy Mulls Sale Options Amid Financial Pressures\n",
    "Article 4 currently scraped:  US Crude Exports Could Suffer From Syncrude Outage\n",
    "Article 5 currently scraped:  Al-Kaabi: Qatar Prepared to Comply With EU Regulations\n",
    "Article 6 currently scraped:  Oil Prices Rise as Iran Doubt Overshadows Saudi Pledge\n",
    "Article 7 currently scraped:  States Sue EPA Over Changes to Emissions Rules\n",
    "Article 8 currently scraped:  EIA: Lower 48 Oil Output Ascends to 10.5 Million b/d\n",
    "Article 9 currently scraped:  Exxon, Chevron CEOs Assail Trump Trade Policies\n",
    "Article 10 currently scraped:  Judge Throws Out Landmark Climate Case\n",
    "Article 11 currently scraped:  Erdogan Victory Buoys Turkey in Russia, Caspian Gas Games\n",
    "Article 12 currently scraped:  Solar, Wind Quickly Catching Up on Cost\n",
    "Article 13 currently scraped:  Security Scare Rattles Mozambique LNG\n",
    "Article 14 currently scraped:  Editorial: Opec Makes a Move\n",
    "Article 15 currently scraped:  European Offshore Wind Players Vie for US Northeast Leases\n",
    "Article 16 currently scraped:  Mounting Uncertainties Require Opec to Stay Nimble\n",
    "Article 17 currently scraped:  Super-Laterals, Cost Controls Help Appalachian E&Ps Thrive in $3 Market\n",
    "Time report: It took 300.118485 seconds to run this script\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IHS Markit - Energy\n",
    "> https://my.ihs.com/Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# Script for scraping text from articles from IHS Markit-Energy website\n",
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "URL = \"https://my.ihs.com/Energy?ForceLogin=True\" # initial page with the login form\n",
    "DATA_FOLDER = \"scraped_IHS\" # folder to save the scraped aricles\n",
    "USERNAME = \"n.ghodke@shell.com\"\n",
    "PASSWORD = \"Forintern1\"\n",
    "\n",
    "\n",
    "browser = webdriver.Chrome(executable_path=os.path.abspath(\"chromedriver\")) #replace with .Firefox(), or with the browser of your choice\n",
    "# The chromdriver executable needs to be in the same folder as this script\n",
    "browser.get(URL) # navigate to the page\n",
    "\n",
    "username = browser.find_element_by_id(\"txtUsername\") #username form field\n",
    "password = browser.find_element_by_id(\"txtPassword\") #password form field\n",
    "\n",
    "\n",
    "username.send_keys(USERNAME) # populate the form\n",
    "if password.is_displayed():\n",
    "\t# if password is not visible (cached) this will not be executed\n",
    "\tpassword.send_keys(PASSWORD)\n",
    "\n",
    "\n",
    "submitButton = browser.find_element_by_id(\"btnSubmit\") \n",
    "submitButton.click()  # submit the login info\n",
    "\n",
    "#Navigate to Energy News on Demand page\n",
    "browser.get(\"https://penod.ihsenergy.com/ENOD/Home#\")\n",
    "\n",
    "\n",
    "articles = browser.find_elements_by_class_name('visitedlink')\n",
    "#print(\"articles found: \", articles)\n",
    "articles = [article for article in articles if \".pdf\" not in article.get_attribute('href')]\n",
    "urls = [i.get_attribute('href') for i in articles] # urls of articles\n",
    "\n",
    "print(\"Number of articles to be scraped: \", len(urls))\n",
    "\n",
    "i=0\n",
    "# iterate through article links\n",
    "for url in urls:\n",
    "\n",
    "\tbrowser.get(url)  \n",
    "\tscraped_text = \"\"\n",
    "\ttitle=browser.find_element_by_xpath(\"/html/body/div[3]/h1\")\n",
    "\tprint(\"Article \" + str(i+1) + \" currently scraped: \", title.text)\n",
    "\tscraped_text += title.text + \"\\n\"\n",
    "\tparagraphs = browser.find_elements_by_class_name(\"MsoNormal\")\n",
    "\tfor p in paragraphs:\n",
    "\t\tscraped_text += p.text +\"\\n\"\n",
    "\n",
    "\ttimestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\twith open(os.path.join(DATA_FOLDER,\"doc_\"+ timestr + \"_\" + \".txt\"), 'w') as d:\n",
    "\t\td.write(scraped_text) # write the scraped text in a document\n",
    "\n",
    "\ti+=1\n",
    "\n",
    "\n",
    "print(\"Time report: It took \" +str((datetime.now() - startTime).total_seconds())+ \" seconds to run this script\")\n",
    "time.sleep(1)\n",
    "browser.quit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: \n",
    "```\n",
    "Number of articles to be scraped:  10\n",
    "Article 1 currently scraped:  New horizontal drilling slated for Arkansas Pennsylvanian pool By Ed Marker\n",
    "Article 2 currently scraped:  Great Plains stakes southern Cambridge Arch basement test By Ed Marker\n",
    "Article 3 currently scraped:  New horizontal drilling slated for Arkansas Pennsylvanian pool By Ed Marker\n",
    "Article 4 currently scraped:  Suemaur adds to northern Kansas exploration program By Ed Marker\n",
    "Article 5 currently scraped:  Two Woodford tests staked on northwestern McClain County pad By Ed Marker\n",
    "Article 6 currently scraped:  Strand Energy sets pipe at 9610-ft Smith County wildcat By Marc Eckhardt, Jeff Gosmano\n",
    "Article 7 currently scraped:  Cobra Oil & Gas drills apparent producer in Angelina County By Jeff Gosmano\n",
    "Article 8 currently scraped:  W&T Offshore to bypass Viosca Knoll test in Virgo field By Marc Eckhardt, Jeff Gosmano\n",
    "Article 9 currently scraped:  U.S. Energy stakes 4500-ft eastern Williamson County test By Jeff Gosmano\n",
    "Article 10 currently scraped:  EnLink plans new Delaware Basin crude oil gathering system By Marc Eckhardt\n",
    "Time report: It took 89.284134 seconds to run this script\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World Energy News\n",
    "> https://www.worldenergynews.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# Script for scraping text from articles from World Energy News website\n",
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "URL = \"https://www.worldenergynews.com/\" # initial page with the login form\n",
    "DATA_FOLDER = \"scraped_WEN\" # folder to save the scraped aricles\n",
    "TIMEOUT = 40\n",
    "\n",
    "browser = webdriver.Chrome(executable_path=os.path.abspath(\"chromedriver\")) #replace with .Firefox(), or with the browser of your choice\n",
    "# The chromdriver executable needs to be in the same folder as this script\n",
    "browser.get(URL) # navigate to the page\n",
    "\n",
    "urls = []\n",
    "latest_news = browser.find_elements_by_class_name('grayscale')\n",
    "for article in latest_news:\n",
    "\t#print(article.get_attribute('innerHTML'))\n",
    "\ta = article.find_element_by_tag_name(\"a\")\n",
    "\turls.append(a.get_attribute('href'))\n",
    "\n",
    "articles = browser.find_elements_by_class_name(\"a\")\n",
    "for article in articles:\n",
    "\turls.append(article.get_attribute('href'))\n",
    "\n",
    "print(\"Number of articles to be scraped: \", len(urls))\n",
    "i=0\n",
    "# iterate through article links\n",
    "for url in urls:\n",
    "\n",
    "\tbrowser.get(url)  \n",
    "\tscraped_text = \"\"\n",
    "\ttry:\n",
    "\t\tWebDriverWait(browser, TIMEOUT).until(EC.visibility_of_element_located((By.XPATH,'//*[@id=\"wrapper\"]/div[2]/div[1]/div/div/article/h1')))\n",
    "\texcept TimeoutException:\n",
    "\t\tprint(\"Timed out waiting for page to load\")\n",
    "\t\tbrowser.quit()\n",
    "\n",
    "\ttitle=browser.find_element_by_xpath('//*[@id=\"wrapper\"]/div[2]/div[1]/div/div/article/h1')\n",
    "\tprint(\"Article \" + str(i+1) + \" currently scraped: \", title.text)\n",
    "\tscraped_text += title.text + \"\\n\"\n",
    "\tparagraphs = browser.find_elements_by_xpath(\"//div[@itemprop='text']\")\n",
    "\n",
    "\tfor p in paragraphs:\n",
    "\t\tscraped_text += p.text +\"\\n\"\n",
    "\n",
    "\ttimestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\twith open(os.path.join(DATA_FOLDER,\"doc_\"+ timestr+ \"_\" + \".txt\"), 'w') as d:\n",
    "\t\td.write(scraped_text) # write the scraped text in a document\n",
    "\n",
    "\ti+=1\n",
    "\n",
    "\n",
    "print(\"Time report: It took \" +str((datetime.now() - startTime).total_seconds())+ \" seconds to run this script\")\n",
    "time.sleep(1)\n",
    "browser.quit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "Number of articles to be scraped:  44\n",
    "Article 1 currently scraped:  EnerMech Obtains $24m Service Contract\n",
    "Article 2 currently scraped:  The Culture Clash Behind GE's Exit from Baker Hughes\n",
    "Article 3 currently scraped:  Goldman Sachs Investment Division Upbeat on Oil\n",
    "Article 4 currently scraped:  Gas to Overtake Oil as Primary Energy Source by Mid-2030s\n",
    "Article 5 currently scraped:  Canada Dreams of Oil Exports to Asia, but California Beckons\n",
    "Article 6 currently scraped:  MAN D&T Rebrands ‘MAN Energy Solutions’\n",
    "Article 7 currently scraped:  Trelleborg Solutions to FSRU-Based LNG Terminal\n",
    "Article 8 currently scraped:  MOL's FSRU Challenger for Hong Kong LNG Terminal Project\n",
    "Article 9 currently scraped:  Offshore Energy: LR Supports Mozambique FLNG Project\n",
    "Article 10 currently scraped:  Idemitsu Founding Family to Accept Showa Shell Merger\n",
    "Article 11 currently scraped:  Oil Rises on Supply Losses, U.S. Push to Isolate Iran\n",
    "Article 12 currently scraped:  GE to Divest Baker Hughes Stake\n",
    "Article 13 currently scraped:  U.S. Court Dismisses Climate Change Lawsuits Against Oil Majors\n",
    "Article 14 currently scraped:  Maritime Decarbonization: The Path Starts in Norway\n",
    "Article 15 currently scraped:  EPA Proposes 2019 Biofuel Requirements\n",
    "Article 16 currently scraped:  U.S. Coal Cargo Reaches China, Beating Import Tariff Deadline\n",
    "Article 17 currently scraped:  Equinor Installs World’s First Battery for Offshore Wind\n",
    "Article 18 currently scraped:  Woodside Mulls Texas Sempra LNG Exit\n",
    "Article 19 currently scraped:  ExxonMobil Mulls \"multi-billion\" Dollar Singapore Refinery Expansion\n",
    "Article 20 currently scraped:  Libya's Internationally Recognized Government Pans Oil Port Decision\n",
    "Article 21 currently scraped:  Airborne, Subsea 7 Launch TCP Riser Program\n",
    "Article 22 currently scraped:  Oil Steady as Outages Balance Trade Dispute, OPEC\n",
    "Article 23 currently scraped:  Europe Distillates-Cracks Rise Despite Wave of Imports\n",
    "Article 24 currently scraped:  PLAT-I: Renewable Energy for Canada\n",
    "Article 25 currently scraped:  Oil Stocks Drop by Nearly 10 mln Barrels - EIA\n",
    "Article 26 currently scraped:  Chevron, Exxon CEOs Worry Global Trade Conflict Could Harm Economy\n",
    "Article 27 currently scraped:  Oil Rises as Outages Balance Trade Dispute, OPEC\n",
    "Article 28 currently scraped:  Oil Producer Deal May Be Short of What's Needed\n",
    "Article 29 currently scraped:  Total, Singapore's Pavilion Energy Sign LNG Ship Fuel Supply Chain Deal\n",
    "Article 30 currently scraped:  Russia's Novatek, S.Korea's Kogas Sign LNG Agreement\n",
    "Article 31 currently scraped:  Croatia Reopens Bidding for LNG Terminal Capacity\n",
    "Article 32 currently scraped:  LNG to Benefit Philippines, Says ADB Energy Expert\n",
    "Article 33 currently scraped:  Oil Rises on Supply Losses, U.S. Push to Isolate Iran\n",
    "Article 34 currently scraped:  Macron Approves Offshore Windpower Projects\n",
    "Article 35 currently scraped:  EU Agrees Final Energy Saving, Renewables Targets\n",
    "Article 36 currently scraped:  China Ramping Up Renewable Power\n",
    "Article 37 currently scraped:  DNV GL Unveils Renewable Energy Data Platform\n",
    "Article 38 currently scraped:  US Announces $18.5 Mln for Offshore Wind Research\n",
    "Article 39 currently scraped:  GTT Studying Gravity Based Systems for LNG Projects\n",
    "Article 40 currently scraped:  New Clamp Technology for Subsea Well Intervention\n",
    "Article 41 currently scraped:  U.S. Pushes Allies to Halt Iran Oil Imports\n",
    "Article 42 currently scraped:  Idemitsu Founding Family to Accept Showa Shell Merger\n",
    "Article 43 currently scraped:  Minnesota Regulators Question Enbridge Pipeline Expansion\n",
    "Article 44 currently scraped:  Venezuela's Creditors Call for Unity\n",
    "Time report: It took 245.9154 seconds to run this script\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
